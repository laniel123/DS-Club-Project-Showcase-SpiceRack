{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "991ac42c",
   "metadata": {},
   "source": [
    "# Spicerack: A Recipe Recommendation System Based on Users Spices   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d090058b",
   "metadata": {},
   "source": [
    "## General Info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ae9284",
   "metadata": {},
   "source": [
    "### Background:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed683233",
   "metadata": {},
   "source": [
    "Background: A common problem I run into when shopping for groceries is completely forgetting what spices I already have at home. I’ll stand in the spice aisle, unsure whether I need anything, which often leads me to buy duplicates or skip the real spices I actually need. Other times, I end up with a single spice that doesn’t really pair with anything else I own, so it just sits in the pantry unused. Over time, this creates clutter, wasted money, and limits what I’m able to cook. While not a life-threatening issue, this project aims to introduce a quality-of-life feature that addresses it by helping users understand which spices they already have, how they relate to one another, and how they can be combined into consistent flavor profiles and practical recipes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0ff795",
   "metadata": {},
   "source": [
    "### Functionality:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4985f099",
   "metadata": {},
   "source": [
    "Users will input the spices they currently have in their pantry. The system will analyze these spices to identify flavor profiles and common pairings. Based on these profiles, the application will recommend recipes that can be made with the user’s existing spices, as well as suggest complementary spices and recipes to expand their cooking options. The focus is on simplicity and usability, allowing users to quickly see how their spices can be used without needing extensive cooking knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d77b67",
   "metadata": {},
   "source": [
    "### Tech Stack & Data: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f5f802",
   "metadata": {},
   "source": [
    "As of right now, the project will be built using Python for data processing and modeling. Libraries such as pandas and NumPy will be used for data handling, while scikit-learn or similar tools may be used for clustering and similarity analysis of flavor profiles. Recipe and spice data will be sourced from Kaggle or publicly available datasets such as recipe APIs or open food databases. The final product may be presented through a simple web interface or notebook based demo. If there is enough time, I hope to present the project with a fully developed app. Implementing this step will be last, as none of us knows any app development. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef20d513",
   "metadata": {},
   "source": [
    "### Proposed Timeline (subject to change)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f0aa35",
   "metadata": {},
   "source": [
    "\n",
    "Week of 1/27 – Exploratory Data Analysis & Dataset Selection\n",
    "\n",
    " Research and select appropriate spice and recipe datasets.\n",
    "\n",
    "Week of 2/3 – Model Building\n",
    "\n",
    "Begin researching and implementing the initial logic for mapping spices to flavor profiles, and begin implementing similarity or clustering methods. Start building a preliminary recommendation approach based on the available data.\n",
    "\n",
    "\n",
    "Week of 2/12 – Dataset & Preliminary Model Deliverable\n",
    "\n",
    "Finalize cleaned datasets and submit an initial working model that demonstrates basic spice analysis and recipe recommendation functionality.\n",
    "\n",
    "\n",
    "Week of 2/17 – Iteration & Feature Expansion\n",
    "\n",
    " Use feedback from the preliminary model to improve accuracy and usability. Refine flavor profile mappings, improve recommendations\n",
    "\n",
    "\n",
    "Week of 2/24 – Midpoint Showcase\n",
    "\n",
    " Prepare and present a functional mid-project demo showcasing current progress, model behavior, and planned next steps.\n",
    "\n",
    "\n",
    "Week of 3/3 – Polishing & User Experience Improvements\n",
    "\n",
    " Focus on improving usability, presentation, and overall flow of the system. Refine outputs and prepare for People’s Choice considerations if applicable.\n",
    "\n",
    "\n",
    "March–May – Final Improvements & Presentation Prep\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9f8e54",
   "metadata": {},
   "source": [
    "## The Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cdf075",
   "metadata": {},
   "source": [
    "### Imports and configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d98b7132",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Preliminary Spice → Recipe Recommender (RecipeNLG-friendly)\n",
    "\n",
    "What this does:\n",
    "1) Loads a RecipeNLG-style CSV \n",
    "2) Extracts spices from each recipe's ingredient text using a spice vocabulary\n",
    "3) Builds a binary spice matrix (recipes x spices)\n",
    "4) Recommends recipes for a user's spice list using Jaccard similarity\n",
    "\n",
    "Notes:\n",
    "- This is a baseline model (no ML training). Perfect for your \"preliminary model\" deliverable.\n",
    "- Works best if you sample down to 50k–200k recipes for speed on a laptop.\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import pairwise_distances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a17ad444",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) CONFIG: spice vocabulary\n",
    "\n",
    "# We will start with 30–80 common spices. Then Expand later.\n",
    "SPICES = [\n",
    "    \"salt\", \"black pepper\", \"pepper\",\n",
    "    \"garlic\", \"garlic powder\",\n",
    "    \"onion powder\", \"onion\",\n",
    "    \"cumin\", \"paprika\", \"smoked paprika\",\n",
    "    \"chili powder\", \"crushed red pepper\", \"red pepper flakes\",\n",
    "    \"cayenne\", \"turmeric\", \"coriander\",\n",
    "    \"ginger\", \"ground ginger\",\n",
    "    \"cinnamon\", \"nutmeg\", \"cloves\", \"allspice\",\n",
    "    \"oregano\", \"basil\", \"thyme\", \"rosemary\", \"sage\",\n",
    "    \"bay leaf\", \"bay leaves\",\n",
    "    \"parsley\",\n",
    "    \"cardamom\", \"fennel\", \"mustard\", \"mustard powder\",\n",
    "    \"curry powder\", \"garam masala\",\n",
    "    \"star anise\", \"anise\",\n",
    "    \"tarragon\", \"dill\",\n",
    "    \"sumac\", \"za'atar\",\n",
    "]\n",
    "\n",
    "# Optional: common names and generalizations. \n",
    "# Note: CHANGE THIS IF NEEDED LATER\n",
    "ALIASES = {\n",
    "    \"bay leaves\": \"bay leaf\",\n",
    "    \"red pepper flakes\": \"crushed red pepper\",\n",
    "    \"ground ginger\": \"ginger\",\n",
    "    \"garlic powder\": \"garlic\",\n",
    "    \"smoked paprika\": \"paprika\",\n",
    "    \"pepper\": \"black pepper\",  # if you want \"pepper\" to map to black pepper\n",
    "}\n",
    "\n",
    "# If you want to avoid matching very generic things (salt/pepper),\n",
    "# you can exclude them later or downweight them in future iterations.\n",
    "# For now we will keep them (baseline).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4de0de7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2) Text cleaning utilities\n",
    "\n",
    "_word_re = re.compile(r\"[a-z]+\")\n",
    "\n",
    "def normalize_text(s: str) -> str:\n",
    "    \"\"\"Lowercase and remove weird chars; keep letters/spaces.\"\"\"\n",
    "    if not isinstance(s, str):\n",
    "        return \"\"\n",
    "    s = s.lower()\n",
    "    # Replace punctuation with spaces\n",
    "    s = re.sub(r\"[^a-z\\s]\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def build_spice_patterns(spice_list):\n",
    "    \"\"\"\n",
    "    Compile regex patterns for spices with word boundaries.\n",
    "    Sort by length so multi-word spices match before single words.\n",
    "    \"\"\"\n",
    "    spices_sorted = sorted(spice_list, key=len, reverse=True)\n",
    "    patterns = []\n",
    "    for sp in spices_sorted:\n",
    "        sp_norm = normalize_text(sp)\n",
    "        # word boundary-ish match on spaces:\n",
    "        # \\b doesn't work perfectly with multi-word; we use: (^| )sp( |$)\n",
    "        pat = re.compile(rf\"(^| ){re.escape(sp_norm)}( |$)\")\n",
    "        patterns.append((sp, sp_norm, pat))\n",
    "    return patterns\n",
    "\n",
    "SPICE_PATTERNS = build_spice_patterns(SPICES)\n",
    "\n",
    "def extract_spices_from_ingredients(ingredients) -> set:\n",
    "    \"\"\"\n",
    "    ingredients: can be a list of ingredient strings OR one big string.\n",
    "    Returns: a set of normalized spice names.\n",
    "    \"\"\"\n",
    "    # If list -> join\n",
    "    if isinstance(ingredients, list):\n",
    "        raw = \" \".join([str(x) for x in ingredients])\n",
    "    else:\n",
    "        raw = str(ingredients)\n",
    "\n",
    "    text = normalize_text(raw)\n",
    "\n",
    "    found = set()\n",
    "    for original, norm, pat in SPICE_PATTERNS:\n",
    "        if pat.search(\" \" + text + \" \"):\n",
    "            found.add(norm)\n",
    "\n",
    "    # Apply alias mapping to canonical names (optional)\n",
    "    canonical = set()\n",
    "    for sp in found:\n",
    "        canonical.add(normalize_text(ALIASES.get(sp, sp)))\n",
    "\n",
    "    return canonical\n",
    "\n",
    "def parse_ingredients_field(x):\n",
    "    \"\"\"\n",
    "    RecipeNLG ingredients are often stored as a stringified Python list like:\n",
    "    \"['1 cup sugar', '2 eggs', ...]\"\n",
    "    If that's your case, try to parse safely.\n",
    "    If it's already a list, we keep it.\n",
    "    If it's plain text, we keep it as text.\n",
    "    \"\"\"\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "\n",
    "    if not isinstance(x, str):\n",
    "        return \"\"\n",
    "\n",
    "    s = x.strip()\n",
    "\n",
    "    # Heuristic: looks like a python list\n",
    "    if s.startswith(\"[\") and s.endswith(\"]\"):\n",
    "        # Very lightweight parsing: pull quoted chunks\n",
    "        # Works for many Kaggle-ish list strings.\n",
    "        items = re.findall(r\"'([^']*)'|\\\"([^\\\"]*)\\\"\", s)\n",
    "        parsed = []\n",
    "        for a, b in items:\n",
    "            parsed.append(a if a else b)\n",
    "        # If parsing fails, fall back to raw string\n",
    "        return parsed if len(parsed) > 0 else x\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5157aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Load the data\n",
    "def load_recipes(csv_path: str, sample_n: int | None = 100_000, seed: int = 42) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Expected columns:\n",
    "      - title (string)\n",
    "      - ingredients (list-like string OR list OR text)\n",
    "    If your file uses different column names, adjust below.\n",
    "\n",
    "    sample_n: set to None to use full dataset (not recommended at first).\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Common RecipeNLG-ish column names:\n",
    "    # Some files use \"title\", \"ingredients\", \"directions\"/\"instructions\".\n",
    "    # If yours differs, rename here.\n",
    "    required = [\"title\", \"ingredients\"]\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(\n",
    "            f\"Missing required columns: {missing}. \"\n",
    "            f\"Your columns are: {list(df.columns)}. \"\n",
    "            f\"Rename columns to include {required}.\"\n",
    "        )\n",
    "\n",
    "    # Sample for speed\n",
    "    if sample_n is not None and len(df) > sample_n:\n",
    "        df = df.sample(n=sample_n, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "    # Parse ingredients field to list/text\n",
    "    df[\"ingredients_parsed\"] = df[\"ingredients\"].apply(parse_ingredients_field)\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cddf84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Build spice matrix\n",
    "def build_spice_matrix(df: pd.DataFrame) -> tuple[pd.DataFrame, MultiLabelBinarizer, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      - df_with_spices: original df + \"spices\" column (set)\n",
    "      - mlb: fitted MultiLabelBinarizer\n",
    "      - X: binary matrix (n_recipes x n_spices) as a numpy array (0/1)\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df[\"spices\"] = df[\"ingredients_parsed\"].apply(extract_spices_from_ingredients)\n",
    "\n",
    "    # Fit binarizer on spice vocabulary (to ensure fixed columns)\n",
    "    spice_vocab = [normalize_text(s) for s in SPICES]\n",
    "    spice_vocab = [normalize_text(ALIASES.get(s, s)) for s in spice_vocab]\n",
    "    spice_vocab = sorted(set(spice_vocab))\n",
    "\n",
    "    mlb = MultiLabelBinarizer(classes=spice_vocab)\n",
    "    X = mlb.fit_transform(df[\"spices\"])\n",
    "\n",
    "    return df, mlb, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9db2556b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Recommend with Jaccard\n",
    "\n",
    "def recommend_recipes(\n",
    "    df: pd.DataFrame,\n",
    "    mlb: MultiLabelBinarizer,\n",
    "    X: np.ndarray,\n",
    "    user_spices: list[str],\n",
    "    top_k: int = 10,\n",
    "    min_match: int = 1\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    user_spices: list of spices the user has (strings)\n",
    "    top_k: number of recommendations\n",
    "    min_match: require at least this many shared spices to show up\n",
    "\n",
    "    Output: ranked dataframe with similarity score and matched spices\n",
    "    \"\"\"\n",
    "    # Normalize + alias\n",
    "    user_norm = [normalize_text(s) for s in user_spices]\n",
    "    user_norm = [normalize_text(ALIASES.get(s, s)) for s in user_norm]\n",
    "    user_set = set(user_norm)\n",
    "\n",
    "    # Build user vector in same feature space\n",
    "    user_vec = mlb.transform([user_set])  # shape (1, n_spices)\n",
    "\n",
    "    # Jaccard distance -> similarity = 1 - distance\n",
    "    # pairwise_distances supports metric=\"jaccard\" on boolean/binary arrays.\n",
    "    # Returns (1, n_recipes)\n",
    "    distances = pairwise_distances(user_vec, X, metric=\"jaccard\")\n",
    "    sims = 1.0 - distances.flatten()\n",
    "\n",
    "    # Compute match counts for filtering/explainability\n",
    "    # Intersection count: (user_vec & recipe_vec).sum()\n",
    "    match_counts = (X & user_vec).sum(axis=1)\n",
    "\n",
    "    # Filter by minimum overlap\n",
    "    valid_idx = np.where(match_counts >= min_match)[0]\n",
    "    if len(valid_idx) == 0:\n",
    "        # No matches -> return best overall (even if 0 overlap)\n",
    "        valid_idx = np.arange(len(df))\n",
    "\n",
    "    # Rank by similarity then by match count\n",
    "    rank_idx = valid_idx[np.lexsort((-match_counts[valid_idx], -sims[valid_idx]))]\n",
    "    rank_idx = rank_idx[:top_k]\n",
    "\n",
    "    out = df.loc[rank_idx, [\"title\"]].copy()\n",
    "    out[\"similarity\"] = sims[rank_idx]\n",
    "    out[\"matched_spices\"] = df.loc[rank_idx, \"spices\"].apply(lambda s: sorted(list(s & user_set)))\n",
    "    out[\"num_matched\"] = match_counts[rank_idx]\n",
    "    out = out.sort_values([\"similarity\", \"num_matched\"], ascending=False).reset_index(drop=True)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "634e6f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top recommendations:\n",
      "                                    title  similarity                                                matched_spices  num_matched\n",
      "                                  Chorizo    0.857143 [black pepper, chili powder, cumin, garlic, oregano, paprika]            6\n",
      "                          Beef Tamale Pie    0.857143 [black pepper, chili powder, cumin, garlic, oregano, paprika]            6\n",
      "Spicy Beer Braised Beef And Buffalo Chili    0.750000 [black pepper, chili powder, cumin, garlic, oregano, paprika]            6\n",
      "                          Chicken Fajitas    0.750000 [black pepper, chili powder, cumin, garlic, oregano, paprika]            6\n",
      "                Ultimate Vegetarian Chili    0.750000 [black pepper, chili powder, cumin, garlic, oregano, paprika]            6\n",
      "          Southwestern Pasta with Chicken    0.750000 [black pepper, chili powder, cumin, garlic, oregano, paprika]            6\n",
      "                     Beef And Pork Chili     0.750000 [black pepper, chili powder, cumin, garlic, oregano, paprika]            6\n",
      "          Chili'S Southwest Chicken Chili    0.750000 [black pepper, chili powder, cumin, garlic, oregano, paprika]            6\n",
      "                     Chuck Shoulder Chili    0.750000 [black pepper, chili powder, cumin, garlic, oregano, paprika]            6\n",
      "                     Chipotle Black Beans    0.750000 [black pepper, chili powder, cumin, garlic, oregano, paprika]            6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/pairwise.py:2466: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# 6) Example run\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 1) Point this to your downloaded RecipeNLG CSV\n",
    "    # Example: \"RecipeNLG_dataset.csv\"\n",
    "    CSV_PATH = \"/Users/daniellarson/Desktop/SpiceRack/cookingdataset/RecipeNLG_dataset.csv\"  # <-- change this based on your user/ file location for now\n",
    "\n",
    "    # Load + sample\n",
    "    df = load_recipes(CSV_PATH, sample_n=100_000)\n",
    "\n",
    "    # Build matrix\n",
    "    df_sp, mlb, X = build_spice_matrix(df)\n",
    "\n",
    "    # Example user input\n",
    "    user_spices = [\"garlic\", \"cumin\", \"paprika\", \"chili powder\", \"oregano\", \"pepper\"]\n",
    "\n",
    "    # Recommend\n",
    "    recs = recommend_recipes(\n",
    "        df=df_sp,\n",
    "        mlb=mlb,\n",
    "        X=X,\n",
    "        user_spices=user_spices,\n",
    "        top_k=10,\n",
    "        min_match=2\n",
    "    )\n",
    "\n",
    "    print(\"\\nTop recommendations:\")\n",
    "    print(recs.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
